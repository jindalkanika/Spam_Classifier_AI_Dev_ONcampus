{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "# !pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation = (open(r\"C:\\Users\\Admin\\Downloads\\spambase\\spambase.DOCUMENTATION\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Title:  SPAM E-mail Database\\n',\n",
       " '\\n',\n",
       " '2. Sources:\\n',\n",
       " '   (a) Creators: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt\\n',\n",
       " '        Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304\\n',\n",
       " '   (b) Donor: George Forman (gforman at nospam hpl.hp.com)  650-857-7835\\n',\n",
       " '   (c) Generated: June-July 1999\\n',\n",
       " '\\n',\n",
       " '3. Past Usage:\\n',\n",
       " '   (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.\\n',\n",
       " '   (b) Determine whether a given email is spam or not.\\n',\n",
       " '   (c) ~7% misclassification error.\\n',\n",
       " '       False positives (marking good mail as spam) are very undesirable.\\n',\n",
       " '       If we insist on zero false positives in the training/testing set,\\n',\n",
       " '       20-25% of the spam passed through the filter.\\n',\n",
       " '\\n',\n",
       " '4. Relevant Information:\\n',\n",
       " '        The \"spam\" concept is diverse: advertisements for products/web\\n',\n",
       " '        sites, make money fast schemes, chain letters, pornography...\\n',\n",
       " '\\tOur collection of spam e-mails came from our postmaster and \\n',\n",
       " '\\tindividuals who had filed spam.  Our collection of non-spam \\n',\n",
       " '\\te-mails came from filed work and personal e-mails, and hence\\n',\n",
       " \"\\tthe word 'george' and the area code '650' are indicators of \\n\",\n",
       " '\\tnon-spam.  These are useful when constructing a personalized \\n',\n",
       " '\\tspam filter.  One would either have to blind such non-spam \\n',\n",
       " '\\tindicators or get a very wide collection of non-spam to \\n',\n",
       " '\\tgenerate a general purpose spam filter.\\n',\n",
       " '\\n',\n",
       " '        For background on spam:\\n',\n",
       " '        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! \\n',\n",
       " '        Communications of the ACM, 41(8):74-83, 1998.\\n',\n",
       " '\\n',\n",
       " '5. Number of Instances: 4601 (1813 Spam = 39.4%)\\n',\n",
       " '\\n',\n",
       " '6. Number of Attributes: 58 (57 continuous, 1 nominal class label)\\n',\n",
       " '\\n',\n",
       " '7. Attribute Information:\\n',\n",
       " \"The last column of 'spambase.data' denotes whether the e-mail was \\n\",\n",
       " 'considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\n',\n",
       " 'Most of the attributes indicate whether a particular word or\\n',\n",
       " 'character was frequently occuring in the e-mail.  The run-length\\n',\n",
       " 'attributes (55-57) measure the length of sequences of consecutive \\n',\n",
       " 'capital letters.  For the statistical measures of each attribute, \\n',\n",
       " 'see the end of this file.  Here are the definitions of the attributes:\\n',\n",
       " '\\n',\n",
       " '48 continuous real [0,100] attributes of type word_freq_WORD \\n',\n",
       " '= percentage of words in the e-mail that match WORD,\\n',\n",
       " 'i.e. 100 * (number of times the WORD appears in the e-mail) / \\n',\n",
       " 'total number of words in e-mail.  A \"word\" in this case is any \\n',\n",
       " 'string of alphanumeric characters bounded by non-alphanumeric \\n',\n",
       " 'characters or end-of-string.\\n',\n",
       " '\\n',\n",
       " '6 continuous real [0,100] attributes of type char_freq_CHAR\\n',\n",
       " '= percentage of characters in the e-mail that match CHAR,\\n',\n",
       " 'i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\n',\n",
       " '\\n',\n",
       " '1 continuous real [1,...] attribute of type capital_run_length_average\\n',\n",
       " '= average length of uninterrupted sequences of capital letters\\n',\n",
       " '\\n',\n",
       " '1 continuous integer [1,...] attribute of type capital_run_length_longest\\n',\n",
       " '= length of longest uninterrupted sequence of capital letters\\n',\n",
       " '\\n',\n",
       " '1 continuous integer [1,...] attribute of type capital_run_length_total\\n',\n",
       " '= sum of length of uninterrupted sequences of capital letters\\n',\n",
       " '= total number of capital letters in the e-mail\\n',\n",
       " '\\n',\n",
       " '1 nominal {0,1} class attribute of type spam\\n',\n",
       " '= denotes whether the e-mail was considered spam (1) or not (0), \\n',\n",
       " 'i.e. unsolicited commercial e-mail.  \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '8. Missing Attribute Values: None\\n',\n",
       " '\\n',\n",
       " '9. Class Distribution:\\n',\n",
       " '\\tSpam\\t  1813  (39.4%)\\n',\n",
       " '\\tNon-Spam  2788  (60.6%)\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Attribute Statistics:\\n',\n",
       " '   Min: Max:   Average:  Std.Dev: Coeff.Var_%: \\n',\n",
       " '1  0    4.54   0.10455   0.30536  292          \\n',\n",
       " '2  0    14.28  0.21301   1.2906   606          \\n',\n",
       " '3  0    5.1    0.28066   0.50414  180          \\n',\n",
       " '4  0    42.81  0.065425  1.3952   2130         \\n',\n",
       " '5  0    10     0.31222   0.67251  215          \\n',\n",
       " '6  0    5.88   0.095901  0.27382  286          \\n',\n",
       " '7  0    7.27   0.11421   0.39144  343          \\n',\n",
       " '8  0    11.11  0.10529   0.40107  381          \\n',\n",
       " '9  0    5.26   0.090067  0.27862  309          \\n',\n",
       " '10 0    18.18  0.23941   0.64476  269          \\n',\n",
       " '11 0    2.61   0.059824  0.20154  337          \\n',\n",
       " '12 0    9.67   0.5417    0.8617   159          \\n',\n",
       " '13 0    5.55   0.09393   0.30104  320          \\n',\n",
       " '14 0    10     0.058626  0.33518  572          \\n',\n",
       " '15 0    4.41   0.049205  0.25884  526          \\n',\n",
       " '16 0    20     0.24885   0.82579  332          \\n',\n",
       " '17 0    7.14   0.14259   0.44406  311          \\n',\n",
       " '18 0    9.09   0.18474   0.53112  287          \\n',\n",
       " '19 0    18.75  1.6621    1.7755   107          \\n',\n",
       " '20 0    18.18  0.085577  0.50977  596          \\n',\n",
       " '21 0    11.11  0.80976   1.2008   148          \\n',\n",
       " '22 0    17.1   0.1212    1.0258   846          \\n',\n",
       " '23 0    5.45   0.10165   0.35029  345          \\n',\n",
       " '24 0    12.5   0.094269  0.44264  470          \\n',\n",
       " '25 0    20.83  0.5495    1.6713   304          \\n',\n",
       " '26 0    16.66  0.26538   0.88696  334          \\n',\n",
       " '27 0    33.33  0.7673    3.3673   439          \\n',\n",
       " '28 0    9.09   0.12484   0.53858  431          \\n',\n",
       " '29 0    14.28  0.098915  0.59333  600          \\n',\n",
       " '30 0    5.88   0.10285   0.45668  444          \\n',\n",
       " '31 0    12.5   0.064753  0.40339  623          \\n',\n",
       " '32 0    4.76   0.047048  0.32856  698          \\n',\n",
       " '33 0    18.18  0.097229  0.55591  572          \\n',\n",
       " '34 0    4.76   0.047835  0.32945  689          \\n',\n",
       " '35 0    20     0.10541   0.53226  505          \\n',\n",
       " '36 0    7.69   0.097477  0.40262  413          \\n',\n",
       " '37 0    6.89   0.13695   0.42345  309          \\n',\n",
       " '38 0    8.33   0.013201  0.22065  1670         \\n',\n",
       " '39 0    11.11  0.078629  0.43467  553          \\n',\n",
       " '40 0    4.76   0.064834  0.34992  540          \\n',\n",
       " '41 0    7.14   0.043667  0.3612   827          \\n',\n",
       " '42 0    14.28  0.13234   0.76682  579          \\n',\n",
       " '43 0    3.57   0.046099  0.22381  486          \\n',\n",
       " '44 0    20     0.079196  0.62198  785          \\n',\n",
       " '45 0    21.42  0.30122   1.0117   336          \\n',\n",
       " '46 0    22.05  0.17982   0.91112  507          \\n',\n",
       " '47 0    2.17   0.0054445 0.076274 1400         \\n',\n",
       " '48 0    10     0.031869  0.28573  897          \\n',\n",
       " '49 0    4.385  0.038575  0.24347  631          \\n',\n",
       " '50 0    9.752  0.13903   0.27036  194          \\n',\n",
       " '51 0    4.081  0.016976  0.10939  644          \\n',\n",
       " '52 0    32.478 0.26907   0.81567  303          \\n',\n",
       " '53 0    6.003  0.075811  0.24588  324          \\n',\n",
       " '54 0    19.829 0.044238  0.42934  971          \\n',\n",
       " '55 1    1102.5 5.1915    31.729   611          \\n',\n",
       " '56 1    9989   52.173    194.89   374          \\n',\n",
       " '57 1    15841  283.29    606.35   214          \\n',\n",
       " '58 0    1      0.39404   0.4887   124          \\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " \"This file: 'spambase.DOCUMENTATION' at the UCI Machine Learning Repository\\n\",\n",
       " 'http://www.ics.uci.edu/~mlearn/MLRepository.html\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentation.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = (open(r\"C:\\Users\\Admin\\Downloads\\spambase\\spambase.names\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\\n',\n",
       " '|\\n',\n",
       " '| 48 continuous real [0,100] attributes of type word_freq_WORD \\n',\n",
       " '| = percentage of words in the e-mail that match WORD,\\n',\n",
       " '| i.e. 100 * (number of times the WORD appears in the e-mail) / \\n',\n",
       " '| total number of words in e-mail.  A \"word\" in this case is any \\n',\n",
       " '| string of alphanumeric characters bounded by non-alphanumeric \\n',\n",
       " '| characters or end-of-string.\\n',\n",
       " '|\\n',\n",
       " '| 6 continuous real [0,100] attributes of type char_freq_CHAR\\n',\n",
       " '| = percentage of characters in the e-mail that match CHAR,\\n',\n",
       " '| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\n',\n",
       " '|\\n',\n",
       " '| 1 continuous real [1,...] attribute of type capital_run_length_average\\n',\n",
       " '| = average length of uninterrupted sequences of capital letters\\n',\n",
       " '|\\n',\n",
       " '| 1 continuous integer [1,...] attribute of type capital_run_length_longest\\n',\n",
       " '| = length of longest uninterrupted sequence of capital letters\\n',\n",
       " '|\\n',\n",
       " '| 1 continuous integer [1,...] attribute of type capital_run_length_total\\n',\n",
       " '| = sum of length of uninterrupted sequences of capital letters\\n',\n",
       " '| = total number of capital letters in the e-mail\\n',\n",
       " '|\\n',\n",
       " '| 1 nominal {0,1} class attribute of type spam\\n',\n",
       " '| = denotes whether the e-mail was considered spam (1) or not (0), \\n',\n",
       " '| i.e. unsolicited commercial e-mail.  \\n',\n",
       " '|\\n',\n",
       " \"| For more information, see file 'spambase.DOCUMENTATION' at the\\n\",\n",
       " '| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '1, 0.    | spam, non-spam classes\\n',\n",
       " '\\n',\n",
       " 'word_freq_make:         continuous.\\n',\n",
       " 'word_freq_address:      continuous.\\n',\n",
       " 'word_freq_all:          continuous.\\n',\n",
       " 'word_freq_3d:           continuous.\\n',\n",
       " 'word_freq_our:          continuous.\\n',\n",
       " 'word_freq_over:         continuous.\\n',\n",
       " 'word_freq_remove:       continuous.\\n',\n",
       " 'word_freq_internet:     continuous.\\n',\n",
       " 'word_freq_order:        continuous.\\n',\n",
       " 'word_freq_mail:         continuous.\\n',\n",
       " 'word_freq_receive:      continuous.\\n',\n",
       " 'word_freq_will:         continuous.\\n',\n",
       " 'word_freq_people:       continuous.\\n',\n",
       " 'word_freq_report:       continuous.\\n',\n",
       " 'word_freq_addresses:    continuous.\\n',\n",
       " 'word_freq_free:         continuous.\\n',\n",
       " 'word_freq_business:     continuous.\\n',\n",
       " 'word_freq_email:        continuous.\\n',\n",
       " 'word_freq_you:          continuous.\\n',\n",
       " 'word_freq_credit:       continuous.\\n',\n",
       " 'word_freq_your:         continuous.\\n',\n",
       " 'word_freq_font:         continuous.\\n',\n",
       " 'word_freq_000:          continuous.\\n',\n",
       " 'word_freq_money:        continuous.\\n',\n",
       " 'word_freq_hp:           continuous.\\n',\n",
       " 'word_freq_hpl:          continuous.\\n',\n",
       " 'word_freq_george:       continuous.\\n',\n",
       " 'word_freq_650:          continuous.\\n',\n",
       " 'word_freq_lab:          continuous.\\n',\n",
       " 'word_freq_labs:         continuous.\\n',\n",
       " 'word_freq_telnet:       continuous.\\n',\n",
       " 'word_freq_857:          continuous.\\n',\n",
       " 'word_freq_data:         continuous.\\n',\n",
       " 'word_freq_415:          continuous.\\n',\n",
       " 'word_freq_85:           continuous.\\n',\n",
       " 'word_freq_technology:   continuous.\\n',\n",
       " 'word_freq_1999:         continuous.\\n',\n",
       " 'word_freq_parts:        continuous.\\n',\n",
       " 'word_freq_pm:           continuous.\\n',\n",
       " 'word_freq_direct:       continuous.\\n',\n",
       " 'word_freq_cs:           continuous.\\n',\n",
       " 'word_freq_meeting:      continuous.\\n',\n",
       " 'word_freq_original:     continuous.\\n',\n",
       " 'word_freq_project:      continuous.\\n',\n",
       " 'word_freq_re:           continuous.\\n',\n",
       " 'word_freq_edu:          continuous.\\n',\n",
       " 'word_freq_table:        continuous.\\n',\n",
       " 'word_freq_conference:   continuous.\\n',\n",
       " 'char_freq_;:            continuous.\\n',\n",
       " 'char_freq_(:            continuous.\\n',\n",
       " 'char_freq_[:            continuous.\\n',\n",
       " 'char_freq_!:            continuous.\\n',\n",
       " 'char_freq_$:            continuous.\\n',\n",
       " 'char_freq_#:            continuous.\\n',\n",
       " 'capital_run_length_average: continuous.\\n',\n",
       " 'capital_run_length_longest: continuous.\\n',\n",
       " 'capital_run_length_total:   continuous.\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\Admin\\Downloads\\spambase\\spambase.data\"\n",
    "data = pd.read_csv(file)\n",
    "X = data.iloc[: , :-1].copy()\n",
    "y = data.iloc[: , -1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split(X,y, random_state = RandomState())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guassian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  82.82608695652173\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.94      0.82       380\n",
      "           0       0.95      0.75      0.84       540\n",
      "\n",
      "    accuracy                           0.83       920\n",
      "   macro avg       0.84      0.85      0.83       920\n",
      "weighted avg       0.86      0.83      0.83       920\n",
      "\n",
      "Cross-validation scores:[0.80978261 0.85054348 0.8423913  0.79347826 0.85054348 0.82065217\n",
      " 0.82336957 0.80163043 0.81793478 0.79619565]\n",
      "Average cross-validation score: 0.8207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandomState())\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "(tn, fp, fn, tp) = sklearn.metrics.confusion_matrix(y_test, y_pred,  labels=None, sample_weight=None, normalize=None).ravel()\n",
    "\n",
    "accuracy = tp+tn \n",
    "accuracy_2 = tp+tn+fp+fn\n",
    "total = accuracy/accuracy_2\n",
    "print(\"Accuracy: \",total * 100)\n",
    "\n",
    "matrix = sklearn.metrics.classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "scores = cross_val_score(gnb, X_train, y_train, cv = 10, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation scores:{}'.format(scores))\n",
    "\n",
    "# compute Average cross-validation score\n",
    "\n",
    "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  78.69565217391305\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.70      0.73       372\n",
      "           0       0.80      0.85      0.83       548\n",
      "\n",
      "    accuracy                           0.79       920\n",
      "   macro avg       0.78      0.77      0.78       920\n",
      "weighted avg       0.79      0.79      0.79       920\n",
      "\n",
      "Cross-validation scores:[0.80434783 0.77173913 0.75543478 0.78804348 0.79076087 0.79619565\n",
      " 0.76902174 0.7826087  0.82065217 0.7826087 ]\n",
      "Average cross-validation score: 0.7861\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandomState())\n",
    "Mnb = MultinomialNB()\n",
    "Mnb.fit(X_train, y_train)\n",
    "y_pred = Mnb.predict(X_test)\n",
    "\n",
    "(tn, fp, fn, tp) = sklearn.metrics.confusion_matrix(y_test, y_pred,  labels=None, sample_weight=None, normalize=None).ravel()\n",
    "\n",
    "accuracy = tp+tn \n",
    "accuracy_2 = tp+tn+fp+fn\n",
    "total = accuracy/accuracy_2\n",
    "print(\"Accuracy: \",total * 100)\n",
    "\n",
    "matrix = sklearn.metrics.classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "scores = cross_val_score(Mnb, X_train, y_train, cv = 10, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation scores:{}'.format(scores))\n",
    "\n",
    "# compute Average cross-validation score\n",
    "\n",
    "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  88.80434782608695\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.84      0.85       357\n",
      "           0       0.90      0.92      0.91       563\n",
      "\n",
      "    accuracy                           0.89       920\n",
      "   macro avg       0.88      0.88      0.88       920\n",
      "weighted avg       0.89      0.89      0.89       920\n",
      "\n",
      "Cross-validation scores:[0.88858696 0.88315217 0.89945652 0.87771739 0.89402174 0.89945652\n",
      " 0.89673913 0.86413043 0.87771739 0.88858696]\n",
      "Average cross-validation score: 0.8870\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandomState())\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "(tn, fp, fn, tp) = sklearn.metrics.confusion_matrix(y_test, y_pred,  labels=None, sample_weight=None, normalize=None).ravel()\n",
    "\n",
    "accuracy = tp+tn \n",
    "accuracy_2 = tp+tn+fp+fn\n",
    "total = accuracy/accuracy_2\n",
    "print(\"Accuracy: \",total * 100)\n",
    "\n",
    "matrix = sklearn.metrics.classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "scores = cross_val_score(bnb, X_train, y_train, cv = 10, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation scores:{}'.format(scores))\n",
    "\n",
    "# compute Average cross-validation score\n",
    "\n",
    "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  93.26086956521739\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.88      0.91       336\n",
      "           0       0.93      0.96      0.95       584\n",
      "\n",
      "    accuracy                           0.93       920\n",
      "   macro avg       0.93      0.92      0.93       920\n",
      "weighted avg       0.93      0.93      0.93       920\n",
      "\n",
      "Cross-validation scores:[0.93206522 0.9375     0.92527174 0.9388587  0.94429348]\n",
      "Average cross-validation score: 0.9356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandomState())\n",
    "adaboost = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "adaboost.fit(X_train, y_train)\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "(tn, fp, fn, tp) = sklearn.metrics.confusion_matrix(y_test, y_pred,  labels=None, sample_weight=None, normalize=None).ravel()\n",
    "\n",
    "accuracy = tp+tn \n",
    "accuracy_2 = tp+tn+fp+fn\n",
    "total = accuracy/accuracy_2\n",
    "print(\"Accuracy: \",total * 100)\n",
    "\n",
    "matrix = sklearn.metrics.classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "scores = cross_val_score(adaboost, X_train, y_train, scoring = 'accuracy')\n",
    "\n",
    "print('Cross-validation scores:{}'.format(scores))\n",
    "\n",
    "# compute Average cross-validation score\n",
    "\n",
    "print('Average cross-validation score: {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  95.65217391304348\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.93      0.95       372\n",
      "           0       0.96      0.97      0.96       548\n",
      "\n",
      "    accuracy                           0.96       920\n",
      "   macro avg       0.96      0.95      0.95       920\n",
      "weighted avg       0.96      0.96      0.96       920\n",
      "\n",
      "Cross-validation scores:[0.95923913 0.95652174 0.94021739 0.9361413  0.94429348]\n",
      "Average cross-validation score: 0.9473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandomState())\n",
    "randomForest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "randomForest.fit(X_train, y_train)\n",
    "y_pred = randomForest.predict(X_test)\n",
    "\n",
    "(tn, fp, fn, tp) = sklearn.metrics.confusion_matrix(y_test, y_pred,  labels=None, sample_weight=None, normalize=None).ravel()\n",
    "\n",
    "accuracy = tp+tn \n",
    "accuracy_2 = tp+tn+fp+fn\n",
    "total = accuracy/accuracy_2\n",
    "print(\"Accuracy: \",total * 100)\n",
    "\n",
    "matrix = sklearn.metrics.classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "random_scores = cross_val_score(randomForest, X_train, y_train, scoring = 'accuracy')\n",
    "\n",
    "print('Cross-validation scores:{}'.format(random_scores))\n",
    "\n",
    "# compute Average cross-validation score\n",
    "\n",
    "print('Average cross-validation score: {:.4f}'.format(random_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 57) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 57), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (1, 57).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 57) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 57), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (1, 57).\n",
      "3680/3680 [==============================] - 4s 857us/step - loss: 0.4435 - accuracy: 0.8043\n",
      "Epoch 2/10\n",
      "3680/3680 [==============================] - 3s 779us/step - loss: 0.2029 - accuracy: 0.9306\n",
      "Epoch 3/10\n",
      "3680/3680 [==============================] - 4s 979us/step - loss: 0.2027 - accuracy: 0.9223\n",
      "Epoch 4/10\n",
      "3680/3680 [==============================] - 3s 907us/step - loss: 0.1812 - accuracy: 0.9313\n",
      "Epoch 5/10\n",
      "3680/3680 [==============================] - 3s 917us/step - loss: 0.1492 - accuracy: 0.9472\n",
      "Epoch 6/10\n",
      "3680/3680 [==============================] - 3s 847us/step - loss: 0.1743 - accuracy: 0.9400\n",
      "Epoch 7/10\n",
      "3680/3680 [==============================] - 3s 810us/step - loss: 0.1639 - accuracy: 0.9415\n",
      "Epoch 8/10\n",
      "3680/3680 [==============================] - 3s 808us/step - loss: 0.1470 - accuracy: 0.9480\n",
      "Epoch 9/10\n",
      "3680/3680 [==============================] - 3s 812us/step - loss: 0.1562 - accuracy: 0.9436\n",
      "Epoch 10/10\n",
      "3680/3680 [==============================] - 4s 1ms/step - loss: 0.1413 - accuracy: 0.9477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x296f2a45c40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandomState())\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test) \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, activation='relu', input_shape=(1,57)))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(X_train, y_train,epochs=10, batch_size=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 57) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 57), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 57).\n",
      "Accuracy:  92.06521739130434\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.87      0.89       354\n",
      "           0       0.92      0.95      0.94       566\n",
      "\n",
      "    accuracy                           0.92       920\n",
      "   macro avg       0.92      0.91      0.92       920\n",
      "weighted avg       0.92      0.92      0.92       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "(tn, fp, fn, tp) = sklearn.metrics.confusion_matrix(y_test, y_pred,  labels=None, sample_weight=None, normalize=None).ravel()\n",
    "\n",
    "accuracy = tp+tn \n",
    "accuracy_2 = tp+tn+fp+fn\n",
    "total = accuracy/accuracy_2\n",
    "print(\"Accuracy: \",total * 100)\n",
    "\n",
    "matrix = sklearn.metrics.classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Hence best model is RandomForestClassifier with highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error = []\n",
    "total_scores = []\n",
    "total_accuracy = []\n",
    "total_random = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------FOR 1 fold---------------\n",
      "Error:  5.0\n",
      "Classification report for 1 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.92      0.94       184\n",
      "           0       0.95      0.97      0.96       276\n",
      "\n",
      "    accuracy                           0.95       460\n",
      "   macro avg       0.95      0.95      0.95       460\n",
      "weighted avg       0.95      0.95      0.95       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.94323671 0.93599034 0.96135266 0.96618357 0.8321256 ]\n",
      "Average cross-validation score: 0.9278 \n",
      "---------------FOR 2 fold---------------\n",
      "Error:  3.4782608695652186\n",
      "Classification report for 2 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.94      0.95       173\n",
      "           0       0.97      0.98      0.97       287\n",
      "\n",
      "    accuracy                           0.97       460\n",
      "   macro avg       0.97      0.96      0.96       460\n",
      "weighted avg       0.97      0.97      0.97       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.9468599  0.94444444 0.95652174 0.97222222 0.82246377]\n",
      "Average cross-validation score: 0.9285 \n",
      "---------------FOR 3 fold---------------\n",
      "Error:  2.608695652173907\n",
      "Classification report for 3 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.96      0.97       183\n",
      "           0       0.97      0.99      0.98       277\n",
      "\n",
      "    accuracy                           0.97       460\n",
      "   macro avg       0.97      0.97      0.97       460\n",
      "weighted avg       0.97      0.97      0.97       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.93599034 0.93599034 0.96135266 0.96618357 0.83695652]\n",
      "Average cross-validation score: 0.9273 \n",
      "---------------FOR 4 fold---------------\n",
      "Error:  4.347826086956516\n",
      "Classification report for 4 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.94      0.95       202\n",
      "           0       0.95      0.97      0.96       258\n",
      "\n",
      "    accuracy                           0.96       460\n",
      "   macro avg       0.96      0.95      0.96       460\n",
      "weighted avg       0.96      0.96      0.96       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.94806763 0.93961353 0.95048309 0.96980676 0.83454106]\n",
      "Average cross-validation score: 0.9285 \n",
      "---------------FOR 5 fold---------------\n",
      "Error:  3.2608695652173907\n",
      "Classification report for 5 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.94      0.96       180\n",
      "           0       0.96      0.98      0.97       280\n",
      "\n",
      "    accuracy                           0.97       460\n",
      "   macro avg       0.97      0.96      0.97       460\n",
      "weighted avg       0.97      0.97      0.97       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.95048309 0.94202899 0.95048309 0.96859903 0.8321256 ]\n",
      "Average cross-validation score: 0.9287 \n",
      "---------------FOR 6 fold---------------\n",
      "Error:  4.565217391304344\n",
      "Classification report for 6 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.93      0.95       194\n",
      "           0       0.95      0.97      0.96       266\n",
      "\n",
      "    accuracy                           0.95       460\n",
      "   macro avg       0.95      0.95      0.95       460\n",
      "weighted avg       0.95      0.95      0.95       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.9384058  0.94565217 0.95289855 0.97222222 0.82729469]\n",
      "Average cross-validation score: 0.9273 \n",
      "---------------FOR 7 fold---------------\n",
      "Error:  5.0\n",
      "Classification report for 7 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.92      0.93       166\n",
      "           0       0.95      0.97      0.96       294\n",
      "\n",
      "    accuracy                           0.95       460\n",
      "   macro avg       0.95      0.94      0.95       460\n",
      "weighted avg       0.95      0.95      0.95       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.94927536 0.93719807 0.96618357 0.96859903 0.83574879]\n",
      "Average cross-validation score: 0.9314 \n",
      "---------------FOR 8 fold---------------\n",
      "Error:  4.347826086956516\n",
      "Classification report for 8 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.93      0.94       178\n",
      "           0       0.95      0.98      0.96       282\n",
      "\n",
      "    accuracy                           0.96       460\n",
      "   macro avg       0.96      0.95      0.95       460\n",
      "weighted avg       0.96      0.96      0.96       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.94565217 0.94202899 0.95652174 0.97101449 0.84661836]\n",
      "Average cross-validation score: 0.9324 \n",
      "---------------FOR 9 fold---------------\n",
      "Error:  4.782608695652172\n",
      "Classification report for 9 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.92      0.93       164\n",
      "           0       0.96      0.97      0.96       296\n",
      "\n",
      "    accuracy                           0.95       460\n",
      "   macro avg       0.95      0.95      0.95       460\n",
      "weighted avg       0.95      0.95      0.95       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.94082126 0.94082126 0.95410628 0.97222222 0.84178744]\n",
      "Average cross-validation score: 0.9300 \n",
      "---------------FOR 10 fold---------------\n",
      "Error:  5.0\n",
      "Classification report for 10 fold: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.93      0.94       188\n",
      "           0       0.95      0.97      0.96       272\n",
      "\n",
      "    accuracy                           0.95       460\n",
      "   macro avg       0.95      0.95      0.95       460\n",
      "weighted avg       0.95      0.95      0.95       460\n",
      "\n",
      "\n",
      "Cross-validation scores:[0.9468599  0.94082126 0.96014493 0.9673913  0.82608696]\n",
      "Average cross-validation score: 0.9283 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "fold_Var = 1\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "fold_Var = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    data_train = data.iloc[train_index]\n",
    "    data_test = data.iloc[test_index]\n",
    "    \n",
    "    X_train = data_train.iloc[: , :-1].copy()\n",
    "    y_train = data_train.iloc[: , -1:].copy()\n",
    "    \n",
    "    X_test = data_test.iloc[: , :-1].copy()\n",
    "    y_test = data_test.iloc[: , -1:].copy()\n",
    "    \n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandomState())\n",
    "    randomForest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "    randomForest.fit(X_train, y_train)\n",
    "    y_pred = randomForest.predict(X_test)\n",
    "\n",
    "    (tn, fp, fn, tp) = sklearn.metrics.confusion_matrix(y_test, y_pred,  labels=None, sample_weight=None, normalize=None).ravel()\n",
    "\n",
    "    accuracy = tp+tn \n",
    "    accuracy_2 = tp+tn+fp+fn\n",
    "    total = accuracy/accuracy_2\n",
    "    error = 100 - total*100\n",
    "    \n",
    "    print (\"---------------FOR {} fold---------------\".format(fold_Var))\n",
    "    print(\"Error: \",100 - total * 100)\n",
    "\n",
    "    matrix = sklearn.metrics.classification_report(y_test,y_pred,labels=[1,0])\n",
    "    print('Classification report for {} fold: \\n{}\\n'.format(fold_Var, matrix))\n",
    "\n",
    "    random_scores = cross_val_score(randomForest, X_train, y_train, scoring = 'accuracy')\n",
    "\n",
    "    print('Cross-validation scores:{}'.format(random_scores))\n",
    "\n",
    "    # compute Average cross-validation score\n",
    "\n",
    "    print('Average cross-validation score: {:.4f} '.format(random_scores.mean()))\n",
    "    fold_Var += 1\n",
    "    total_error.append(error)\n",
    "    total_scores.append((tn, fp, fn, tp))\n",
    "    total_accuracy.append(random_scores.mean())\n",
    "    total_random.append(random_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['Fold'] = ['1st','2nd','3rd','4th','5th', '6th', '7th', '8th', '9th', '10th']\n",
    "output['Error'] = total_error\n",
    "output['(tn, fp, fn, tp)'] = total_scores  \n",
    "output['Average Cross Validation Score'] = total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Error</th>\n",
       "      <th>(tn, fp, fn, tp)</th>\n",
       "      <th>Average Cross Validation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>(267, 9, 14, 170)</td>\n",
       "      <td>0.927778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>(281, 6, 10, 163)</td>\n",
       "      <td>0.928502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd</td>\n",
       "      <td>2.608696</td>\n",
       "      <td>(273, 4, 8, 175)</td>\n",
       "      <td>0.927295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>(250, 8, 12, 190)</td>\n",
       "      <td>0.928502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th</td>\n",
       "      <td>3.260870</td>\n",
       "      <td>(275, 5, 10, 170)</td>\n",
       "      <td>0.928744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6th</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>(258, 8, 13, 181)</td>\n",
       "      <td>0.927295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7th</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>(285, 9, 14, 152)</td>\n",
       "      <td>0.931401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8th</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>(275, 7, 13, 165)</td>\n",
       "      <td>0.932367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9th</td>\n",
       "      <td>4.782609</td>\n",
       "      <td>(287, 9, 13, 151)</td>\n",
       "      <td>0.929952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10th</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>(263, 9, 14, 174)</td>\n",
       "      <td>0.928261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold     Error   (tn, fp, fn, tp)  Average Cross Validation Score\n",
       "0   1st  5.000000  (267, 9, 14, 170)                        0.927778\n",
       "1   2nd  3.478261  (281, 6, 10, 163)                        0.928502\n",
       "2   3rd  2.608696   (273, 4, 8, 175)                        0.927295\n",
       "3   4th  4.347826  (250, 8, 12, 190)                        0.928502\n",
       "4   5th  3.260870  (275, 5, 10, 170)                        0.928744\n",
       "5   6th  4.565217  (258, 8, 13, 181)                        0.927295\n",
       "6   7th  5.000000  (285, 9, 14, 152)                        0.931401\n",
       "7   8th  4.347826  (275, 7, 13, 165)                        0.932367\n",
       "8   9th  4.782609  (287, 9, 13, 151)                        0.929952\n",
       "9  10th  5.000000  (263, 9, 14, 174)                        0.928261"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output  # tn = true negative, fp = false positive, fn = false negative, tp = true positive\n",
    "        # Eroor = 100 - [(tp+tn)/ (tn + fp + tp + fp)] * 100 (error)\n",
    "        # Average cross validation score = mean of cross val scores in the particular fold\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Error in Random Forest Classifier: 4.239130434782607\n"
     ]
    }
   ],
   "source": [
    "Average_error = 0\n",
    "for x in total_error:\n",
    "    Average_error = Average_error + x\n",
    "Average_error = Average_error/10.0\n",
    "print (\"Average Error in Random Forest Classifier: {}\".format(Average_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy on best model: 95.76086956521739 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy on best model: {} %\".format(100 - Average_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----USING RANDOM FOREST CLASSIFIER FROM SKLEARN ENSEMBLE METHODS WITH 10-FOLD CROSS VALIDATION----\n",
      "\n",
      "   Fold     Error   (tn, fp, fn, tp)  Average Cross Validation Score\n",
      "0   1st  5.000000  (267, 9, 14, 170)                        0.927778\n",
      "1   2nd  3.478261  (281, 6, 10, 163)                        0.928502\n",
      "2   3rd  2.608696   (273, 4, 8, 175)                        0.927295\n",
      "3   4th  4.347826  (250, 8, 12, 190)                        0.928502\n",
      "4   5th  3.260870  (275, 5, 10, 170)                        0.928744\n",
      "5   6th  4.565217  (258, 8, 13, 181)                        0.927295\n",
      "6   7th  5.000000  (285, 9, 14, 152)                        0.931401\n",
      "7   8th  4.347826  (275, 7, 13, 165)                        0.932367\n",
      "8   9th  4.782609  (287, 9, 13, 151)                        0.929952\n",
      "9  10th  5.000000  (263, 9, 14, 174)                        0.928261\n",
      " \n",
      "Average Error in Random Forest Classifier: 4.239130434782607\n",
      "Average accuracy on best model: 95.76086956521739%\n"
     ]
    }
   ],
   "source": [
    "print(\"-----USING RANDOM FOREST CLASSIFIER FROM SKLEARN ENSEMBLE METHODS WITH 10-FOLD CROSS VALIDATION----\")\n",
    "print(\"\")\n",
    "print(output)\n",
    "print(\" \")\n",
    "print (\"Average Error in Random Forest Classifier: {}\".format(Average_error))\n",
    "print(\"Average accuracy on best model: {}%\".format(100 - Average_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
